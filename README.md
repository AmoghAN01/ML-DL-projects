# ML-projects
This is a repository to show my machine learning and deep learning projects.  
The projects:

1] Credit card Dimensionality Reduction using Autoencoders

This project implements an autoencoder for dimensionality reduction on the "Default of Credit Card Clients" dataset from the UCI Machine Learning Repository. The dataset consists of 30,000 samples with 24 features related to credit card usage and default prediction. The autoencoder architecture compresses the input features from 24 to 16 dimensions while preserving key information, achieving a Mean Squared Error (MSE) of 0.0011 and an RÂ² score of approximately 0.66 on both training and test datasets. The use of MinMaxScaler for feature scaling, along with techniques like LeakyReLU activation and dropout for regularization, ensures effective training and generalization. Overall, the model demonstrates a successful reduction in dimensionality while retaining significant variance from the original dataset.

2] Customer segmentation

This project focuses on customer segmentation using K-means clustering to analyze spending patterns based on income levels. The Jupyter notebook contains code for loading and preprocessing customer data from a CSV file, performing exploratory data analysis, and implementing K-means clustering to segment customers into distinct groups. The analysis utilizes Python libraries such as pandas, numpy, matplotlib, and scikit-learn. The methodology involves determining the optimal number of clusters using the elbow method and visualizing the results through scatter plots. The final output segments customers into four distinct groups based on their income and spending patterns, which can be leveraged for targeted marketing strategies or personalized customer experiences

3] EDA

This project explores the UCI Adult dataset through comprehensive Exploratory Data Analysis (EDA), revealing significant demographic and income insights. The analysis uncovers that approximately 24% of individuals earn more than $50K, with males substantially overrepresented in the high-income category (30% vs. 10% for females). Key findings highlight age trends showing high-income individuals tend to be older, with males averaging 44.63 years and females 42.13 years. Additionally, the study demonstrates gender disparities in work patterns, with males working an average of 42.43 hours per week compared to females' 36.41 hours, while both genders maintain a median of 40 work hours weekly. The research methodology involved rigorous data preprocessing, statistical analysis, and visualization techniques to extract meaningful patterns across gender, age, and income dimensions, with future goals including machine learning model development and deeper exploration of education and occupation correlations.

4] EmotionDetectionusingCNN

This project implements an emotion recognition system using a Convolutional Neural Network (CNN) to classify images into seven emotion categories: anger, disgust, fear, happiness, neutral, sadness, and surprise. The system utilizes a dataset of 35,887 labeled grayscale images and employs data preprocessing techniques like normalization, resizing, and augmentation. A custom CNN architecture is designed with convolutional, max-pooling, and fully connected layers, along with dropout layers to mitigate overfitting. The model is trained using categorical cross-entropy loss and optimized with early stopping and learning rate schedulers, achieving an accuracy of around 60%.

5] GAN for digit Generation

This project utilizes a Generative Adversarial Network (GAN) to generate realistic images of the handwritten digit 4, leveraging the MNIST dataset. The GAN consists of a generator, which creates synthetic images from random noise, and a discriminator, which distinguishes between real and generated images. The generator employs dense, batch normalization, and Conv2DTranspose layers to output a 28x28 grayscale image, while the discriminator uses a convolutional neural network for binary classification. Trained with the Adam optimizer and binary cross-entropy loss over 100 epochs, the GAN successfully learns to produce 100 synthetic images that closely resemble the original MNIST digit 4 samples, demonstrating a consistent reduction in generator loss and stable training.

6] Online Food Ordering Behavior Analysis and Prediction

This project analyzes a dataset of 388 online food orders to explore relationships between demographic/location factors and ordering behavior, customer feedback, and predictive modeling. EDA reveals insights like a 77.6% positive feedback rate and geographic trends via latitude/longitude analysis. Visualizations (scatter plots, stacked bar charts) examine factors like age, gender, income, and occupation against order status. A K-Nearest Neighbors (KNN) classifier, trained on encoded features (e.g., Age, Gender, Marital Status), achieves 89.7% accuracy in predicting order behavior. The project uses pandas, matplotlib, and scikit-learn, offering actionable insights for service improvement and customer preference prediction.

7] Spam Classification using ML

This project showcases a powerful SMS spam detection system using multiple machine learning models. Leveraging a dataset of labeled SMS messages, the system employs sophisticated text preprocessing techniques including tokenization, stop word removal, and lemmatization. The cleaned text is then transformed into numerical features using TF-IDF vectorization. Four different classification models - Naive Bayes, Random Forest, K-Nearest Neighbors, and Support Vector Machine - are trained and evaluated. The results are impressive, with accuracies around 97% across all models. Notably, the Random Forest classifier achieves perfect precision and the highest F1-score of 0.893, while the SVM model demonstrates the best recall at 0.833. This project not only demonstrates the effectiveness of machine learning in combating spam but also provides a comprehensive framework for text classification tasks.

8] Stroke Prediction(ML)

This project presents a comprehensive stroke prediction system utilizing machine learning techniques on a healthcare dataset. The analysis begins with a thorough exploratory data analysis (EDA) of a dataset containing 5,110 records and 12 attributes, including demographic, lifestyle, and health-related features. The methodology involves data cleaning, feature categorization, and visualization techniques such as distribution plots and count plots. Statistical analysis, including ANOVA and Chi-square tests, identifies key predictors of stroke risk. The project then implements various machine learning models, including Linear Regression, Random Forest, Gradient Boosting, SVM, and Naive Bayes, using separate pipelines for numerical and categorical features. Results show that age is the most significant factor influencing stroke risk, followed by average glucose level. Among the models, SVM achieves the highest classification accuracy at 93.93%. This project not only demonstrates the power of machine learning in healthcare predictions but also provides valuable insights into stroke risk factors, making it a significant contribution to predictive healthcare analytics.

9] MNIST with wandb(Dl)

This project showcases an MNIST ConvNet Classifier with Weights & Biases (wandb) integration, demonstrating state-of-the-art practices in deep learning. The implementation uses PyTorch to build a Convolutional Neural Network (CNN) for classifying handwritten digits from the MNIST dataset. The CNN architecture consists of two convolutional layers and two fully connected layers, trained using the Adam optimizer over 10 epochs. A key feature is the seamless integration of wandb for comprehensive experiment tracking and visualization. The model achieves impressive results with a test accuracy of 98.95% and a test loss of 0.03433. This project not only highlights the effectiveness of CNNs in image classification tasks but also showcases modern machine learning development techniques, including real-time performance monitoring and analysis through wandb. 
